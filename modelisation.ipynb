{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain\n",
    "\n",
    "import nltk\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import scripts\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"bag\": False,\n",
    "    \"tfidf\": False,\n",
    "    \"unsupervised\": False,\n",
    "    \"supervised\": {\n",
    "        \"knc\": False, # must be False, too greedy\n",
    "        \"dtc\": False, # should be False, long run\n",
    "        \"rfc\": False, # must be False, too long\n",
    "        \"sgd\": False, # should be True\n",
    "        \"lgc\": True # should be True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data_cleaned.csv\", index_col=\"Id\")\n",
    "\n",
    "data[\"Tags\"] = data[\"Tags\"].apply(eval)\n",
    "# data[\"Tokens\"] = data[\"Tokens\"].apply(eval)\n",
    "# data[\"POS\"] = data[\"POS\"].apply(eval)\n",
    "# data[\"Lemmatized\"] = data[\"Lemmatized\"].apply(eval)\n",
    "# data[\"LemmaAndStem\"] = data[\"LemmaAndStem\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Tags\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Tags.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for row in data.Tags.values:\n",
    "    tags += row\n",
    "tags_df = pd.DataFrame(data=tags, columns=[\"Tag\"]).value_counts().reset_index()\n",
    "tags_df.columns = [\"Tag\", \"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "sns.barplot(data=tags_df.iloc[:20], x=\"Tag\", y=\"Count\")\n",
    "\n",
    "plt.title(\"Tag count\", size=20)\n",
    "plt.xlabel(\"Tag\", size=16)\n",
    "plt.ylabel(\"Count\", size=16)\n",
    "plt.xticks(rotation=45, size=16, ha=\"right\")\n",
    "plt.yticks(size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "ax = sns.ecdfplot(data=tags_df, x=\"Count\", log_scale=True)\n",
    "\n",
    "plt.axhline(0.98, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "plt.axvline(200, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "plt.title(\"Cummulative coverage percentage\", size=20)\n",
    "plt.xlabel(\"Number of post\", size=16)\n",
    "plt.ylabel(\"Proportion\", size=16)\n",
    "plt.xticks(rotation=45, size=16, ha=\"right\")\n",
    "plt.yticks(size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = tags_df[:200]\n",
    "tags_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = dict(zip(tags_df.Tag, tags_df.Count))\n",
    "wordcloud = WordCloud(background_color=\"black\", width=1600, height=800).generate_from_frequencies(word_frequencies)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tags_df.Tag.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_or_remove(cell, word_list):\n",
    "    return [word for word in cell if word in word_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tags_Reduced\"] = data.apply(lambda row: find_or_remove(row[\"Tags\"], tags),axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tags_Reduced\"].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(dataset, max_features=None, min_df=0.0, max_df=1.0):\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, stop_words=None, max_features=max_features, max_df=max_df, min_df=min_df)\n",
    "    matrix = vectorizer.fit_transform(dataset)\n",
    "\n",
    "    data_dense = matrix.todense()\n",
    "    print(f\"Sparcity: {((data_dense > 0).sum() / data_dense.size)*100:.4}%\")\n",
    "\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "    matrix = matrix.toarray()\n",
    "    bag = pd.DataFrame(data=matrix, columns=vocab)\n",
    "    return bag, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = None\n",
    "if config[\"bag\"]:\n",
    "    bag = bow(data, \"Sentence\")\n",
    "    display = bag.iloc[:5, :20]\n",
    "display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(dataset, max_features=None, min_df=0.0, max_df=1.0):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=None, stop_words=None, max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "    matrix = vectorizer.fit_transform(dataset).toarray()\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    tfidf = pd.DataFrame(data=matrix, columns=vocab)\n",
    "    return tfidf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = None\n",
    "if config[\"tfidf\"]:\n",
    "    tfidf = tfidf(data, \"Sentence\")\n",
    "    display = tfidf.iloc[:5, :20]\n",
    "display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/#9buildldamodelwithsklearn\n",
    "#\n",
    "def latent_dirichlet_allocation_tuning(dataset: pd.DataFrame, param_grid: dict):\n",
    "    data_bow, vectorizer = bow(dataset, min_df=.005)\n",
    "    feature_names = data_bow.columns\n",
    "\n",
    "    lda = LatentDirichletAllocation()\n",
    "    gs = GridSearchCV(lda, param_grid)\n",
    "    gs.fit(data_bow)\n",
    "\n",
    "    lda_model = gs.best_estimator_\n",
    "    lda_output = lda_model.transform(data_bow)\n",
    "    topic_names = [\"Topic\"+str(i) for i in range(lda_model.n_components)]\n",
    "\n",
    "    lda_output_dataframe = pd.DataFrame(np.round(lda_output, 2), columns=topic_names)\n",
    "\n",
    "    return gs, feature_names, data_bow, vectorizer, lda_output_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_topic(lda_model, data_bow, dataset_row_nb):\n",
    "    lda_output = lda_model.transform(data_bow)\n",
    "\n",
    "    topic_names = [\"Topic\"+str(i) for i in range(lda_model.n_components)]\n",
    "    doc_names = [\"Doc\"+str(i) for i in range(dataset_row_nb)]\n",
    "\n",
    "    df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "    dominant_topics = np.argmax(df_document_topic.values, axis=1)\n",
    "    df_document_topic[\"Dominant_Topic\"] = dominant_topics\n",
    "\n",
    "    return df_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution(dominant_topic_df):\n",
    "    distribution = dominant_topic_df[\"Dominant_Topic\"].value_counts().reset_index()\n",
    "    distribution.columns = [\"Dominant_Topic\", \"Count\"]\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    sns.countplot(data=dominant_topic_df, x=\"Dominant_Topic\")\n",
    "\n",
    "    plt.title(\"Tag count\", size=20)\n",
    "    plt.xlabel(\"Tag\", size=16)\n",
    "    plt.ylabel(\"Count\", size=16)\n",
    "    plt.xticks(rotation=45, size=16, ha=\"right\")\n",
    "    plt.yticks(size=16)\n",
    "    plt.show()\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_words(lda_model, feature_names, n_words=20):\n",
    "    keywords = np.array(feature_names)\n",
    "    topic_keywords = []\n",
    "    for topic_weight in lda_model.components_:\n",
    "        topic_keyword_locs = (-topic_weight).argsort()[:n_words]\n",
    "        topic_keywords.append(feature_names.take(topic_keyword_locs))\n",
    "    \n",
    "    topic_keywords_df = pd.DataFrame(data=topic_keywords)\n",
    "    topic_keywords_df.columns = [\"Word\"+str(i) for i in range(topic_keywords_df.shape[1])]\n",
    "    topic_keywords_df.index = [\"Topic\"+str(i) for i in range(topic_keywords_df.shape[0])]\n",
    "    return topic_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(lda_model, sentence, vectorizer, topic_keywords_dataset):\n",
    "    sentence = scripts.preprocess_sentence(sentence)\n",
    "    data_bow = vectorizer.transform([sentence])\n",
    "    topic_probability_score = lda_model.transform(data_bow)\n",
    "    topic = topic_keywords_dataset.iloc[np.argmax(topic_probability_score), :]\n",
    "    topic_name = topic.name\n",
    "    topic_words = topic.values.tolist()\n",
    "    return topic_name, topic_words, topic_probability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_tuning_post_lda(dataset_X: pd.DataFrame, dataset_y: pd.DataFrame, meta_model, model, param_grid: dict, scoring: str = \"f1_micro\"):\n",
    "    start = datetime.now()\n",
    "\n",
    "    # target multi label binarizer\n",
    "    multi_label_binarizer = MultiLabelBinarizer()\n",
    "    y = multi_label_binarizer.fit_transform(dataset_y)\n",
    "\n",
    "    feature_names = dataset_X.columns\n",
    "    classes = multi_label_binarizer.classes_\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset_X, y, test_size = 0.33, random_state = 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # multioutput or onevsrest ...\n",
    "    meta_model.fit(X_train, y_train)\n",
    "\n",
    "    # gridsearch tuning/fitting\n",
    "    gs = GridSearchCV(meta_model, param_grid, scoring=scoring, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # advanced evaluation\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"classifier_tuning > Time taken to run this cell : {datetime.now() - start} \\n\")\n",
    "\n",
    "    return gs, classes, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gs, classes, y_test, y_pred):\n",
    "    start = datetime.now()\n",
    "\n",
    "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming loss \", hamming_loss(y_test, y_pred))\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))\n",
    "\n",
    "    print(f\"evaluate > Time taken to run this cell : {datetime.now() - start}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 6.1 Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    param_grid = {\n",
    "        \"n_components\": [10],\n",
    "        \"learning_decay\": [.7],\n",
    "        \"random_state\": [0],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    gs, feature_names, data_bow, vectorizer, lda_output_dataframe = latent_dirichlet_allocation_tuning(data[\"Sentence\"], param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    print(f\"Log likelihood: {gs.best_estimator_.score(data_bow)}\")\n",
    "    print(f\"Perplexity: {gs.best_estimator_.perplexity(data_bow)}\")\n",
    "    print(f\"Best params: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    dominant_topic_df = get_dominant_topic(gs.best_estimator_, data_bow, data.shape[0])\n",
    "    dominant_topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_distribution(dominant_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_keywords_df = pd.DataFrame(data=gs.best_estimator_.components_, columns=feature_names, index=dominant_topic_df.columns[:-1])\n",
    "    topic_keywords_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_keywords_df.iloc[:, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_keywords_dataset = topic_words(lda_model=gs.best_estimator_, feature_names=feature_names, n_words=20)\n",
    "    topic_keywords_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    sentence = \"<p>I want to create a sql script to<code>something</code> automatise the data seeding</p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_name, topic_words, topic_probability_score = make_prediction(lda_model=gs.best_estimator_, sentence=sentence, vectorizer=vectorizer, topic_keywords_dataset=topic_keywords_dataset)\n",
    "    topic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"unsupervised\"]:\n",
    "    param_grid = {\n",
    "        \"estimator__solver\": [\"liblinear\"],\n",
    "        \"estimator__penalty\": [\"l1\"],\n",
    "        \"estimator__random_state\": [0],\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    meta_model = OneVsRestClassifier(model)\n",
    "    gs, classes, y_test, y_pred = classifier_tuning_post_lda(lda_output_dataframe, data[\"Tags_Reduced\"], meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 7 Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.codementor.io/@agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu\n",
    "# https://www.kaggle.com/patrickaudriaz/random-forests-for-multiclass-classification\n",
    "# \n",
    "def classifier_tuning(dataset: pd.DataFrame, meta_model, model, param_grid: dict, scoring: str = \"f1_micro\"):\n",
    "    start = datetime.now()\n",
    "\n",
    "    X, vectorizer = tfidf(dataset[\"Sentence\"], min_df=.001, max_df=1.0)\n",
    "\n",
    "    # target multi label binarizer\n",
    "    multi_label_binarizer = MultiLabelBinarizer()\n",
    "    y = multi_label_binarizer.fit_transform(dataset[\"Tags_Reduced\"])\n",
    "\n",
    "    feature_names = X.columns\n",
    "    classes = multi_label_binarizer.classes_\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1)\n",
    "\n",
    "    # multioutput or onevsrest ...\n",
    "    meta_model.fit(X_train, y_train)\n",
    "\n",
    "    # gridsearch tuning/fitting\n",
    "    gs = GridSearchCV(meta_model, param_grid, scoring=scoring, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # advanced evaluation\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"classifier_tuning > Time taken to run this cell : {datetime.now() - start} \\n\")\n",
    "\n",
    "    return gs, classes, y_test, y_pred, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gs, classes, y_test, y_pred):\n",
    "    start = datetime.now()\n",
    "\n",
    "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming loss \", hamming_loss(y_test, y_pred))\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))\n",
    "\n",
    "    print(f\"evaluate > Time taken to run this cell : {datetime.now() - start}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.1 K Neighbors Classifier with MultiOutput Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too greedy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"knc\"]:\n",
    "    param_grid = {\n",
    "        \"estimator__n_neighbors\": [5],\n",
    "        \"estimator__n_jobs\": [10],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    meta_model = MultiOutputClassifier\n",
    "    model = KNeighborsClassifier()\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.2 Decision Tree Classifier with MultiOutput Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"dtc\"]:\n",
    "    param_grid = {\n",
    "        \"estimator__max_depth\": [50],\n",
    "        \"estimator__criterion\": [\"entropy\"],\n",
    "        \"estimator__random_state\": [0],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    meta_model = MultiOutputClassifier\n",
    "    model = DecisionTreeClassifier()\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.3 Random Forest Classifier with MultiOutput Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too long..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"rfc\"]:\n",
    "    param_grid = {\n",
    "        \"estimator__n_estimators\": [100],\n",
    "        \"estimator__max_depth\": [50],\n",
    "        \"estimator__criterion\": [\"entropy\"],\n",
    "        \"estimator__n_jobs\": [10],\n",
    "        \"estimator__random_state\": [0],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    meta_model = MultiOutputClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.4 SGD  with OneVsRest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"sgd\"]:\n",
    "    param_grid = {\n",
    "        \"estimator__loss\": [\"log\"],\n",
    "        \"estimator__alpha\": [0.00001],\n",
    "        \"estimator__penalty\": [\"l1\"],\n",
    "        \"estimator__n_jobs\": [10],\n",
    "        \"estimator__random_state\": [0],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    model = SGDClassifier()\n",
    "    meta_model = OneVsRestClassifier(model)\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.5 Logistic Regression with OneVsRest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_data, vectorizer = tfidf(data[\"Sentence\"], min_df=0.001, max_df=1.0)\n",
    "# tfidf_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf.shape = 2400 * 470000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"lgc\"]:\n",
    "    param_grid = {\n",
    "        # \"estimator__max_iter\": [1000],\n",
    "        # \"estimator__solver\": [\"liblinear\"],\n",
    "        # \"estimator__penalty\": [\"l1\"],\n",
    "        # \"estimator__random_state\": [0],\n",
    "        \"n_jobs\": [10]\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\")\n",
    "    meta_model = OneVsRestClassifier(model)\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"lgc\"]:\n",
    "    param_grid = {\n",
    "        # \"classifier__solver\": [\"liblinear\"],\n",
    "        # \"classifier__penalty\": [\"l1\"],\n",
    "        # \"classifier__random_state\": [0],\n",
    "    }\n",
    "\n",
    "    model = SGDClassifier(max_iter=1000, tol=1e-3, alpha=20, loss=\"modified_huber\", class_weight=\"balanced\")\n",
    "    meta_model = OneVsRestClassifier(model)\n",
    "    gs, classes, y_test, y_pred, vectorizer = classifier_tuning(data, meta_model, model, param_grid)\n",
    "    evaluate(gs, classes, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 7.6 Serializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"supervised\"][\"lgc\"] and False:\n",
    "    with open(\"model.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(gs.best_estimator_, handle, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"tfidf_vectorizer.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(vectorizer, handle, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"labels.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(classes, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
